{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "tutorial.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gt31iAJCab0e"
      },
      "source": [
        "# Searching Efficient 3D Architectures with Sparse Point-Voxel Convolution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6BJlSs6ab0f"
      },
      "source": [
        "In this tutorial, we will introduce how to efficiently segment LiDAR point clouds with our pre-trained SPVNAS."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsDge8DWab0g"
      },
      "source": [
        "Let's first clone the codebase:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtqFLVpeab0g",
        "outputId": "f2df04bd-0d45-45ed-a10d-e7afa289e90d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/mit-han-lab/spvnas.git\n",
        "\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(os.path.join(os.getcwd(), 'spvnas'))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'spvnas'...\n",
            "remote: Enumerating objects: 278, done.\u001b[K\n",
            "remote: Counting objects: 100% (278/278), done.\u001b[K\n",
            "remote: Compressing objects: 100% (166/166), done.\u001b[K\n",
            "remote: Total 278 (delta 139), reused 207 (delta 89), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (278/278), 8.32 MiB | 20.48 MiB/s, done.\n",
            "Resolving deltas: 100% (139/139), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vu-r4Axab0h"
      },
      "source": [
        "Let's then install some libraries. This step might take around 5 minutes on Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yz23WPkCab0h",
        "outputId": "778be850-ec5b-4c36-c4d1-547c989f5df7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!sudo apt-get install libsparsehash-dev 1>/dev/null\n",
        "!pip install --upgrade plotly 1>/dev/null\n",
        "!pip install --upgrade torchpack 1>/dev/null\n",
        "!pip install --upgrade git+https://github.com/mit-han-lab/torchsparse.git 1>/dev/null"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "  Running command git clone -q https://github.com/mit-han-lab/torchsparse.git /tmp/pip-req-build-2lixa4pc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a82Gk6V0ab0h"
      },
      "source": [
        "Let's import some libraries and define constants for visualization:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DI58gNoLab0i"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torchsparse import SparseTensor\n",
        "from torchsparse.utils.quantize import sparse_quantize\n",
        "from torchsparse.utils.collate import sparse_collate\n",
        "\n",
        "COLOR_MAP = np.array(['#f59664', '#f5e664', '#963c1e', '#b41e50', '#ff0000',\n",
        "                      '#1e1eff', '#c828ff', '#5a1e96', '#ff00ff', '#ff96ff',\n",
        "                      '#4b004b', '#4b00af', '#00c8ff', '#3278ff', '#00af00',\n",
        "                      '#003c87', '#50f096', '#96f0ff', '#0000ff', '#ffffff'])\n",
        "\n",
        "LABEL_MAP = np.array([19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 0, 1, 19,\n",
        "                      19, 19, 2, 19, 19, 3, 19, 4, 19, 19, 19, 19, 19,\n",
        "                      19, 19, 19, 19, 5, 6, 7, 19, 19, 19, 19, 19, 19,\n",
        "                      19, 8, 19, 19, 19, 9, 19, 19, 19, 10, 11, 12, 13,\n",
        "                      19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
        "                      19, 19, 19, 19, 19, 14, 15, 16, 19, 19, 19, 19, 19,\n",
        "                      19, 19, 17, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
        "                      19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
        "                      19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
        "                      19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
        "                      19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
        "                      19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
        "                      19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
        "                      19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
        "                      19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
        "                      19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
        "                      19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
        "                      19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
        "                      19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
        "                      19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9VfbwUKab0i"
      },
      "source": [
        "Let's load some real lidar data and pre-process it for inference."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6v9A4zmab0i"
      },
      "source": [
        "# Load the LiDAR data and its label\n",
        "lidar = np.fromfile('spvnas/assets/000000.bin', dtype=np.float32)\n",
        "label = np.fromfile('spvnas/assets/000000.label', dtype=np.int32)\n",
        "lidar = lidar.reshape(-1, 4)\n",
        "label = LABEL_MAP[label & 0xFFFF]\n",
        "\n",
        "# Filter out ignored points\n",
        "lidar = lidar[label != 19]\n",
        "label = label[label != 19]\n",
        "\n",
        "# Quantize coordinates\n",
        "coords = np.round(lidar[:, :3] / 0.05)\n",
        "coords -= coords.min(0, keepdims=1)\n",
        "feats = lidar\n",
        "\n",
        "# Filter out duplicate points\n",
        "coords, indices, inverse = sparse_quantize(coords, return_index=True, return_inverse=True)\n",
        "coords = torch.tensor(coords, dtype=torch.int)\n",
        "feats = torch.tensor(feats[indices], dtype=torch.float)\n",
        "\n",
        "inputs = SparseTensor(coords=coords, feats=feats)\n",
        "inputs = sparse_collate([inputs]).cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RlGolfHab0j"
      },
      "source": [
        "Now, we import the pretrained SPVNAS from our model zoo to run the inference."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "op5Gau7eab0j"
      },
      "source": [
        "from model_zoo import spvnas_specialized\n",
        "\n",
        "# Load the pre-trained model from model zoo\n",
        "model = spvnas_specialized('SemanticKITTI_val_SPVNAS@65GMACs').cuda()\n",
        "model.eval()\n",
        "\n",
        "# Run the inference\n",
        "outputs = model(inputs)\n",
        "outputs = outputs.argmax(1).cpu().numpy()\n",
        "\n",
        "# Map the prediction back to original points\n",
        "outputs = outputs[inverse]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2P1GmOiCab0j"
      },
      "source": [
        "Finally, we visualize the predictions from SPVNAS in an interactive window. Enjoy!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTYCLUrEab0j"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "def configure_plotly_browser_state():\n",
        "    import IPython\n",
        "    display(IPython.core.display.HTML('''\n",
        "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
        "        <script>\n",
        "          requirejs.config({\n",
        "            paths: {\n",
        "              base: '/static/base',\n",
        "              plotly: 'https://cdn.plot.ly/plotly-latest.min.js?noext',\n",
        "            },\n",
        "          });\n",
        "        </script>\n",
        "        '''))\n",
        "\n",
        "import plotly\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "trace = go.Scatter3d(\n",
        "    x=lidar[:, 0],\n",
        "    y=lidar[:, 1],\n",
        "    z=lidar[:, 2],\n",
        "    mode='markers',\n",
        "    marker={\n",
        "        'size': 1,\n",
        "        'opacity': 0.8,\n",
        "        'color': COLOR_MAP[outputs].tolist(),\n",
        "    }\n",
        ")\n",
        "\n",
        "configure_plotly_browser_state()\n",
        "plotly.offline.init_notebook_mode(connected=False)\n",
        "\n",
        "layout = go.Layout(\n",
        "    margin={'l': 0, 'r': 0, 'b': 0, 't': 0},\n",
        "    scene=dict(aspectmode='manual', aspectratio=dict(x=1, y=1, z=0.2))\n",
        ")\n",
        "\n",
        "plotly.offline.iplot(go.Figure(data=[trace], layout=layout))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}